{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfLyricClassifcation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwvSes/DrmO+6cUiHqTkBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "pythonjvsc74a57bd063a8339a2b998405504b80cac15dbfc0480b6c1c806e16474572f1b40b735ee0",
      "display_name": "Python 3.9.5 64-bit ('env': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "63a8339a2b998405504b80cac15dbfc0480b6c1c806e16474572f1b40b735ee0"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benbrill/MoodSpace/blob/main/tfLyricClassifcation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "This notebook outlines the creation of our model to generate Spotify metrics from song lyrics"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gimym_e08Xr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "source": [
        "# Load Training Data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xjv0ShaR1GO1",
        "outputId": "30f3a96c-0385-4517-ef48-d77591c53ecb"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/benbrill/MoodSpace/main/data/trainingSongs_clean.csv\")\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                         trackName          artist  \\\n",
              "0             3                       Overthinker            INZO   \n",
              "1             4   Lifestyles of the Rich & Famous  Good Charlotte   \n",
              "2             6        Carrying Your Love With Me   George Strait   \n",
              "3             7                 Check Yes, Juliet    We The Kings   \n",
              "4             8       At My Worst (feat. Kehlani)     Pink Sweat$   \n",
              "..          ...                               ...             ...   \n",
              "712         994                              90mh        Trefuego   \n",
              "713         995                          9 Bridge     Rowdy Rebel   \n",
              "714         996  Lotus Flower Bomb (feat. Miguel)            Wale   \n",
              "715         997                           Envy Me          Calboy   \n",
              "716         998        Bitch Better Have My Money         Rihanna   \n",
              "\n",
              "                         id  danceability  energy   key  loudness  mode  \\\n",
              "0    4K9xid96G3YmIvQZXN9SXg         0.472   0.605   8.0    -4.437   1.0   \n",
              "1    2g2a5kDeZexbUTD8abcvm6         0.620   0.930   1.0    -3.685   1.0   \n",
              "2    7puxIVNdj5nsBJk43zM3bH         0.629   0.479  10.0   -10.608   1.0   \n",
              "3    0wVluBsVAVzBKrqspuCcwR         0.352   0.912   7.0    -4.253   1.0   \n",
              "4    58w68w4s8h9gw3xrDaXyuj         0.731   0.484   0.0    -5.579   1.0   \n",
              "..                      ...           ...     ...   ...       ...   ...   \n",
              "712  1VxvGm1moDJ3svQlwjdBwA         0.716   0.427   1.0    -8.993   1.0   \n",
              "713  2sHekv6OdEiO4htSjdB9j4         0.642   0.589   5.0    -7.392   0.0   \n",
              "714  3MAgQuClHcAV8E9CbeBS6f         0.512   0.598   9.0    -4.959   0.0   \n",
              "715  7rvyVWja33WG9R97oeJAjx         0.740   0.488   1.0    -7.664   0.0   \n",
              "716  0NTMtAO2BV4tnGvw9EgBVq         0.781   0.728   1.0    -4.981   1.0   \n",
              "\n",
              "     speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
              "0         0.1340       0.03110          0.030800    0.1010    0.212  128.375   \n",
              "1         0.0374       0.00043          0.000000    0.0686    0.609  106.220   \n",
              "2         0.0271       0.22000          0.000000    0.0587    0.345  138.231   \n",
              "3         0.0725       0.00197          0.000000    0.1930    0.351  166.795   \n",
              "4         0.0354       0.73000          0.000003    0.3260    0.350   92.043   \n",
              "..           ...           ...               ...       ...      ...      ...   \n",
              "712       0.0529       0.18700          0.000000    0.3540    0.223  108.993   \n",
              "713       0.3020       0.12400          0.000000    0.0868    0.720   95.543   \n",
              "714       0.1150       0.61100          0.000000    0.0881    0.345   70.189   \n",
              "715       0.2700       0.23400          0.000000    0.2410    0.584  149.042   \n",
              "716       0.0621       0.05090          0.000002    0.2570    0.395  102.990   \n",
              "\n",
              "               type                                             lyrics  \\\n",
              "0    audio_features  a person who thinks all the time has nothing t...   \n",
              "1    audio_features  always see it on t v or read in the magazines ...   \n",
              "2    audio_features  baby all i got is this beat up leather bag and...   \n",
              "3    audio_features  check yes juliet are you with me rain is falli...   \n",
              "4    audio_features  can i call you baby can you be my friend can y...   \n",
              "..              ...                                                ...   \n",
              "712  audio_features  hi kevin ayy yeah ayy ayy you dont really want...   \n",
              "713  audio_features  i know i dont never make promises this time i ...   \n",
              "714  audio_features  ima rap to you real quick i wanna enjoy the lu...   \n",
              "715  audio_features  now i lay me down to sleep now i lay me down t...   \n",
              "716  audio_features  yayo yayo mula la yayo bitch better have my mo...   \n",
              "\n",
              "     cluster language  \n",
              "0          0       en  \n",
              "1          3       en  \n",
              "2          5       en  \n",
              "3          2       en  \n",
              "4          1       en  \n",
              "..       ...      ...  \n",
              "712        3       en  \n",
              "713        1       en  \n",
              "714        4       en  \n",
              "715        5       en  \n",
              "716        1       en  \n",
              "\n",
              "[717 rows x 19 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>trackName</th>\n      <th>artist</th>\n      <th>id</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>type</th>\n      <th>lyrics</th>\n      <th>cluster</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Overthinker</td>\n      <td>INZO</td>\n      <td>4K9xid96G3YmIvQZXN9SXg</td>\n      <td>0.472</td>\n      <td>0.605</td>\n      <td>8.0</td>\n      <td>-4.437</td>\n      <td>1.0</td>\n      <td>0.1340</td>\n      <td>0.03110</td>\n      <td>0.030800</td>\n      <td>0.1010</td>\n      <td>0.212</td>\n      <td>128.375</td>\n      <td>audio_features</td>\n      <td>a person who thinks all the time has nothing t...</td>\n      <td>0</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Lifestyles of the Rich &amp; Famous</td>\n      <td>Good Charlotte</td>\n      <td>2g2a5kDeZexbUTD8abcvm6</td>\n      <td>0.620</td>\n      <td>0.930</td>\n      <td>1.0</td>\n      <td>-3.685</td>\n      <td>1.0</td>\n      <td>0.0374</td>\n      <td>0.00043</td>\n      <td>0.000000</td>\n      <td>0.0686</td>\n      <td>0.609</td>\n      <td>106.220</td>\n      <td>audio_features</td>\n      <td>always see it on t v or read in the magazines ...</td>\n      <td>3</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>Carrying Your Love With Me</td>\n      <td>George Strait</td>\n      <td>7puxIVNdj5nsBJk43zM3bH</td>\n      <td>0.629</td>\n      <td>0.479</td>\n      <td>10.0</td>\n      <td>-10.608</td>\n      <td>1.0</td>\n      <td>0.0271</td>\n      <td>0.22000</td>\n      <td>0.000000</td>\n      <td>0.0587</td>\n      <td>0.345</td>\n      <td>138.231</td>\n      <td>audio_features</td>\n      <td>baby all i got is this beat up leather bag and...</td>\n      <td>5</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>Check Yes, Juliet</td>\n      <td>We The Kings</td>\n      <td>0wVluBsVAVzBKrqspuCcwR</td>\n      <td>0.352</td>\n      <td>0.912</td>\n      <td>7.0</td>\n      <td>-4.253</td>\n      <td>1.0</td>\n      <td>0.0725</td>\n      <td>0.00197</td>\n      <td>0.000000</td>\n      <td>0.1930</td>\n      <td>0.351</td>\n      <td>166.795</td>\n      <td>audio_features</td>\n      <td>check yes juliet are you with me rain is falli...</td>\n      <td>2</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>At My Worst (feat. Kehlani)</td>\n      <td>Pink Sweat$</td>\n      <td>58w68w4s8h9gw3xrDaXyuj</td>\n      <td>0.731</td>\n      <td>0.484</td>\n      <td>0.0</td>\n      <td>-5.579</td>\n      <td>1.0</td>\n      <td>0.0354</td>\n      <td>0.73000</td>\n      <td>0.000003</td>\n      <td>0.3260</td>\n      <td>0.350</td>\n      <td>92.043</td>\n      <td>audio_features</td>\n      <td>can i call you baby can you be my friend can y...</td>\n      <td>1</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>712</th>\n      <td>994</td>\n      <td>90mh</td>\n      <td>Trefuego</td>\n      <td>1VxvGm1moDJ3svQlwjdBwA</td>\n      <td>0.716</td>\n      <td>0.427</td>\n      <td>1.0</td>\n      <td>-8.993</td>\n      <td>1.0</td>\n      <td>0.0529</td>\n      <td>0.18700</td>\n      <td>0.000000</td>\n      <td>0.3540</td>\n      <td>0.223</td>\n      <td>108.993</td>\n      <td>audio_features</td>\n      <td>hi kevin ayy yeah ayy ayy you dont really want...</td>\n      <td>3</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>995</td>\n      <td>9 Bridge</td>\n      <td>Rowdy Rebel</td>\n      <td>2sHekv6OdEiO4htSjdB9j4</td>\n      <td>0.642</td>\n      <td>0.589</td>\n      <td>5.0</td>\n      <td>-7.392</td>\n      <td>0.0</td>\n      <td>0.3020</td>\n      <td>0.12400</td>\n      <td>0.000000</td>\n      <td>0.0868</td>\n      <td>0.720</td>\n      <td>95.543</td>\n      <td>audio_features</td>\n      <td>i know i dont never make promises this time i ...</td>\n      <td>1</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>714</th>\n      <td>996</td>\n      <td>Lotus Flower Bomb (feat. Miguel)</td>\n      <td>Wale</td>\n      <td>3MAgQuClHcAV8E9CbeBS6f</td>\n      <td>0.512</td>\n      <td>0.598</td>\n      <td>9.0</td>\n      <td>-4.959</td>\n      <td>0.0</td>\n      <td>0.1150</td>\n      <td>0.61100</td>\n      <td>0.000000</td>\n      <td>0.0881</td>\n      <td>0.345</td>\n      <td>70.189</td>\n      <td>audio_features</td>\n      <td>ima rap to you real quick i wanna enjoy the lu...</td>\n      <td>4</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>997</td>\n      <td>Envy Me</td>\n      <td>Calboy</td>\n      <td>7rvyVWja33WG9R97oeJAjx</td>\n      <td>0.740</td>\n      <td>0.488</td>\n      <td>1.0</td>\n      <td>-7.664</td>\n      <td>0.0</td>\n      <td>0.2700</td>\n      <td>0.23400</td>\n      <td>0.000000</td>\n      <td>0.2410</td>\n      <td>0.584</td>\n      <td>149.042</td>\n      <td>audio_features</td>\n      <td>now i lay me down to sleep now i lay me down t...</td>\n      <td>5</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>998</td>\n      <td>Bitch Better Have My Money</td>\n      <td>Rihanna</td>\n      <td>0NTMtAO2BV4tnGvw9EgBVq</td>\n      <td>0.781</td>\n      <td>0.728</td>\n      <td>1.0</td>\n      <td>-4.981</td>\n      <td>1.0</td>\n      <td>0.0621</td>\n      <td>0.05090</td>\n      <td>0.000002</td>\n      <td>0.2570</td>\n      <td>0.395</td>\n      <td>102.990</td>\n      <td>audio_features</td>\n      <td>yayo yayo mula la yayo bitch better have my mo...</td>\n      <td>1</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>717 rows Ã— 19 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "source": [
        "# Create Vectorization Layer"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDTSMbEC2Szp"
      },
      "source": [
        "# only the top distinct words will be tracked\n",
        "max_tokens = 2000\n",
        "\n",
        "# establish a vector length of 500\n",
        "sequence_length = 500\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_tokens, # only consider this many words\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbmJ12El3UdI"
      },
      "source": [
        "# adapt the vectorization to work on our song lyrics\n",
        "vectorize_layer.adapt(df['lyrics'].to_numpy())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "source": [
        "# Create Training and Testing Data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Uoq_nRAeum"
      },
      "source": [
        "X = vectorize_layer(df['lyrics']).numpy().astype(\"int32\") # predictor will be a vectorized form of song lyrics\n",
        "y = df[[\"energy\", \"valence\", \"tempo\", \"liveness\"]].to_numpy().astype(\"float32\") # target will be spotify metrics listed"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsYnDCJJBadI"
      },
      "source": [
        "# split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state = 42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "source": [
        "# Create Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdnWkAaW0LaK"
      },
      "source": [
        "lyrics_features = None\n",
        "# set input as the vectorized form of lyrics, each of which is a vector len = 500\n",
        "lyrics_input = keras.Input(\n",
        "    shape = (500,), \n",
        "    name = \"lyrics\",\n",
        "    dtype = \"int32\"\n",
        ")\n",
        "lyrics_features = layers.Embedding(max_tokens, 60, name = \"embedding\")(lyrics_input) # add embedding layer\n",
        "lyrics_features = layers.Dropout(0.2)(lyrics_features)\n",
        "lyrics_features = layers.Conv1D(64, 5, activation='relu')(lyrics_features)\n",
        "lyrics_features = layers.MaxPooling1D(pool_size=4)(lyrics_features)\n",
        "lyrics_features = layers.LSTM(100)(lyrics_features)\n",
        "lyrics_features = layers.Dropout(0.2)(lyrics_features)\n",
        "lyrics_features = layers.Dense(64, activation='relu')(lyrics_features)\n",
        "lyrics_features = layers.Dense(32, activation='relu')(lyrics_features)\n",
        "output1 = layers.Dense(4, name = \"metrics\")(lyrics_features) # create output layer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJLbZcEOCvau"
      },
      "source": [
        "model = keras.Model(inputs=lyrics_input, outputs=[output1]) # create model using layers above"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ww3CO8lY9mOz",
        "outputId": "a866b2bb-d4c1-4dfb-99d6-31312bd567cb"
      },
      "source": [
        "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSTdmOVj-LMm",
        "outputId": "dbdbcc8a-ecee-4e19-9efa-dd1413641923"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlyrics (InputLayer)          [(None, 500)]             0         \n_________________________________________________________________\nembedding (Embedding)        (None, 500, 60)           120000    \n_________________________________________________________________\ndropout (Dropout)            (None, 500, 60)           0         \n_________________________________________________________________\nconv1d (Conv1D)              (None, 496, 64)           19264     \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 124, 64)           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 100)               66000     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                6464      \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                2080      \n_________________________________________________________________\nmetrics (Dense)              (None, 4)                 132       \n=================================================================\nTotal params: 213,940\nTrainable params: 213,940\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy2eT2KXpDii"
      },
      "source": [
        "model.compile(loss='mae',\n",
        "              optimizer='adam', \n",
        "              metrics=['RootMeanSquaredError', 'msle'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX28frVGpFuJ",
        "outputId": "3a0b42fd-d4c3-428e-ef52-1e5344ba4a16",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs = 100, validation_data = (X_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " val_loss: 6.1332 - val_root_mean_squared_error: 14.2607 - val_msle: 0.0273\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 4s 210ms/step - loss: 6.2456 - root_mean_squared_error: 14.8633 - msle: 0.0632 - val_loss: 6.1566 - val_root_mean_squared_error: 14.2509 - val_msle: 0.0353\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 4s 199ms/step - loss: 6.2973 - root_mean_squared_error: 14.9746 - msle: 0.0639 - val_loss: 6.1913 - val_root_mean_squared_error: 14.0896 - val_msle: 0.0477\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 4s 192ms/step - loss: 6.2725 - root_mean_squared_error: 14.7739 - msle: 0.0717 - val_loss: 6.0937 - val_root_mean_squared_error: 14.0343 - val_msle: 0.0455\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 4s 197ms/step - loss: 6.2028 - root_mean_squared_error: 14.5892 - msle: 0.0680 - val_loss: 6.1225 - val_root_mean_squared_error: 13.9667 - val_msle: 0.0806\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 4s 201ms/step - loss: 6.2078 - root_mean_squared_error: 14.6291 - msle: 0.0755 - val_loss: 6.0847 - val_root_mean_squared_error: 14.1110 - val_msle: 0.0333\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 4s 217ms/step - loss: 6.2624 - root_mean_squared_error: 14.8498 - msle: 0.0585 - val_loss: 6.2144 - val_root_mean_squared_error: 14.4629 - val_msle: 0.0278\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 4s 218ms/step - loss: 6.0044 - root_mean_squared_error: 14.6406 - msle: 0.0550 - val_loss: 6.0428 - val_root_mean_squared_error: 14.0049 - val_msle: 0.0537\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 4s 225ms/step - loss: 5.8104 - root_mean_squared_error: 14.0387 - msle: 0.0613 - val_loss: 5.7491 - val_root_mean_squared_error: 14.0112 - val_msle: 0.0365\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 4s 220ms/step - loss: 5.7120 - root_mean_squared_error: 14.0533 - msle: 0.0573 - val_loss: 6.0048 - val_root_mean_squared_error: 14.4180 - val_msle: 0.0357\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 5s 229ms/step - loss: 5.5884 - root_mean_squared_error: 13.7680 - msle: 0.0516 - val_loss: 5.9451 - val_root_mean_squared_error: 14.2972 - val_msle: 0.0325\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 5s 232ms/step - loss: 5.6641 - root_mean_squared_error: 13.8469 - msle: 0.0485 - val_loss: 5.8273 - val_root_mean_squared_error: 14.1141 - val_msle: 0.0421\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 4s 219ms/step - loss: 5.6467 - root_mean_squared_error: 13.8994 - msle: 0.0554 - val_loss: 6.0855 - val_root_mean_squared_error: 14.4774 - val_msle: 0.0451\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 5s 237ms/step - loss: 5.5191 - root_mean_squared_error: 13.6804 - msle: 0.0580 - val_loss: 5.8753 - val_root_mean_squared_error: 14.1374 - val_msle: 0.0293\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 4s 217ms/step - loss: 5.5171 - root_mean_squared_error: 13.6972 - msle: 0.0553 - val_loss: 5.9346 - val_root_mean_squared_error: 14.2263 - val_msle: 0.0391\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 4s 218ms/step - loss: 5.5128 - root_mean_squared_error: 13.5622 - msle: 0.0467 - val_loss: 5.9772 - val_root_mean_squared_error: 14.4129 - val_msle: 0.0292\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 4s 200ms/step - loss: 5.6716 - root_mean_squared_error: 13.9228 - msle: 0.0474 - val_loss: 5.7817 - val_root_mean_squared_error: 14.0910 - val_msle: 0.0362\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 4s 194ms/step - loss: 5.5617 - root_mean_squared_error: 13.6597 - msle: 0.0491 - val_loss: 6.1509 - val_root_mean_squared_error: 14.5806 - val_msle: 0.0459\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 4s 199ms/step - loss: 5.4502 - root_mean_squared_error: 13.4817 - msle: 0.0539 - val_loss: 5.8331 - val_root_mean_squared_error: 14.1115 - val_msle: 0.0309\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 4s 187ms/step - loss: 5.3656 - root_mean_squared_error: 13.5378 - msle: 0.0450 - val_loss: 5.9998 - val_root_mean_squared_error: 14.3315 - val_msle: 0.0418\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 4s 203ms/step - loss: 5.4302 - root_mean_squared_error: 13.4498 - msle: 0.0502 - val_loss: 5.8806 - val_root_mean_squared_error: 14.1955 - val_msle: 0.0495\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 4s 207ms/step - loss: 5.4094 - root_mean_squared_error: 13.4948 - msle: 0.0550 - val_loss: 5.8992 - val_root_mean_squared_error: 14.1729 - val_msle: 0.0335\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 5s 240ms/step - loss: 5.5410 - root_mean_squared_error: 13.8526 - msle: 0.0449 - val_loss: 6.0119 - val_root_mean_squared_error: 14.4427 - val_msle: 0.0307\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 5s 232ms/step - loss: 5.5165 - root_mean_squared_error: 13.8552 - msle: 0.0439 - val_loss: 5.9228 - val_root_mean_squared_error: 14.0521 - val_msle: 0.0554\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 4s 186ms/step - loss: 5.5510 - root_mean_squared_error: 13.7038 - msle: 0.0523 - val_loss: 5.9817 - val_root_mean_squared_error: 14.2813 - val_msle: 0.0417\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 4s 181ms/step - loss: 5.5222 - root_mean_squared_error: 13.8270 - msle: 0.0472 - val_loss: 5.9096 - val_root_mean_squared_error: 14.2987 - val_msle: 0.0342\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 4s 211ms/step - loss: 5.3571 - root_mean_squared_error: 13.5855 - msle: 0.0427 - val_loss: 5.9785 - val_root_mean_squared_error: 14.2901 - val_msle: 0.0283\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 4s 198ms/step - loss: 5.3460 - root_mean_squared_error: 13.5131 - msle: 0.0423 - val_loss: 5.8896 - val_root_mean_squared_error: 14.0693 - val_msle: 0.0412\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 4s 210ms/step - loss: 5.4922 - root_mean_squared_error: 13.6644 - msle: 0.0439 - val_loss: 5.9681 - val_root_mean_squared_error: 14.3172 - val_msle: 0.0295\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 4s 207ms/step - loss: 5.3970 - root_mean_squared_error: 13.4228 - msle: 0.0419 - val_loss: 5.8327 - val_root_mean_squared_error: 13.9862 - val_msle: 0.0327\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 4s 207ms/step - loss: 5.5479 - root_mean_squared_error: 13.6791 - msle: 0.0424 - val_loss: 5.9624 - val_root_mean_squared_error: 14.2211 - val_msle: 0.0361\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 4s 197ms/step - loss: 5.3641 - root_mean_squared_error: 13.4808 - msle: 0.0426 - val_loss: 5.9276 - val_root_mean_squared_error: 14.3018 - val_msle: 0.0345\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 4s 194ms/step - loss: 5.3336 - root_mean_squared_error: 13.4725 - msle: 0.0369 - val_loss: 5.9949 - val_root_mean_squared_error: 14.2421 - val_msle: 0.0469\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 4s 195ms/step - loss: 5.4642 - root_mean_squared_error: 13.5822 - msle: 0.0462 - val_loss: 5.9360 - val_root_mean_squared_error: 14.2410 - val_msle: 0.0365\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 4s 191ms/step - loss: 5.3896 - root_mean_squared_error: 13.5318 - msle: 0.0410 - val_loss: 5.8581 - val_root_mean_squared_error: 14.1658 - val_msle: 0.0321\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 4s 198ms/step - loss: 5.4281 - root_mean_squared_error: 13.6007 - msle: 0.0405 - val_loss: 5.9544 - val_root_mean_squared_error: 14.2715 - val_msle: 0.0313\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 4s 193ms/step - loss: 5.4125 - root_mean_squared_error: 13.5470 - msle: 0.0396 - val_loss: 5.9682 - val_root_mean_squared_error: 14.2120 - val_msle: 0.0535\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 4s 196ms/step - loss: 5.4611 - root_mean_squared_error: 13.5541 - msle: 0.0446 - val_loss: 5.9915 - val_root_mean_squared_error: 14.2735 - val_msle: 0.0633\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 4s 206ms/step - loss: 5.3719 - root_mean_squared_error: 13.3946 - msle: 0.0448 - val_loss: 5.8874 - val_root_mean_squared_error: 14.1686 - val_msle: 0.0311\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 4s 194ms/step - loss: 5.3409 - root_mean_squared_error: 13.3179 - msle: 0.0369 - val_loss: 6.0699 - val_root_mean_squared_error: 14.3513 - val_msle: 0.0473\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 4s 184ms/step - loss: 5.3597 - root_mean_squared_error: 13.5928 - msle: 0.0405 - val_loss: 5.9814 - val_root_mean_squared_error: 14.2114 - val_msle: 0.0593\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 4s 190ms/step - loss: 5.4387 - root_mean_squared_error: 13.4881 - msle: 0.0476 - val_loss: 6.0126 - val_root_mean_squared_error: 14.3108 - val_msle: 0.0616\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 4s 189ms/step - loss: 5.2129 - root_mean_squared_error: 13.2943 - msle: 0.0435 - val_loss: 5.9948 - val_root_mean_squared_error: 14.3510 - val_msle: 0.0351\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 4s 189ms/step - loss: 5.3649 - root_mean_squared_error: 13.4114 - msle: 0.0347 - val_loss: 5.9913 - val_root_mean_squared_error: 14.3533 - val_msle: 0.0333\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 4s 188ms/step - loss: 5.2810 - root_mean_squared_error: 13.3340 - msle: 0.0332 - val_loss: 5.8616 - val_root_mean_squared_error: 14.0905 - val_msle: 0.0453\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 4s 198ms/step - loss: 5.4006 - root_mean_squared_error: 13.4041 - msle: 0.0388 - val_loss: 6.1052 - val_root_mean_squared_error: 14.5772 - val_msle: 0.0330\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 4s 197ms/step - loss: 5.3610 - root_mean_squared_error: 13.5707 - msle: 0.0347 - val_loss: 5.8994 - val_root_mean_squared_error: 14.3478 - val_msle: 0.0324\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 4s 189ms/step - loss: 5.2813 - root_mean_squared_error: 13.4362 - msle: 0.0318 - val_loss: 6.0765 - val_root_mean_squared_error: 14.6635 - val_msle: 0.0291\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 4s 190ms/step - loss: 5.2865 - root_mean_squared_error: 13.3521 - msle: 0.0304 - val_loss: 5.8486 - val_root_mean_squared_error: 14.2022 - val_msle: 0.0361\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 4s 194ms/step - loss: 5.2897 - root_mean_squared_error: 13.2927 - msle: 0.0332 - val_loss: 6.0545 - val_root_mean_squared_error: 14.5874 - val_msle: 0.0445\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 4s 218ms/step - loss: 5.3665 - root_mean_squared_error: 13.6065 - msle: 0.0328 - val_loss: 5.9499 - val_root_mean_squared_error: 14.3047 - val_msle: 0.0333\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 4s 214ms/step - loss: 5.1729 - root_mean_squared_error: 13.1604 - msle: 0.0300 - val_loss: 6.0709 - val_root_mean_squared_error: 14.5266 - val_msle: 0.0383\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 4s 195ms/step - loss: 5.2668 - root_mean_squared_error: 13.2890 - msle: 0.0329 - val_loss: 6.0593 - val_root_mean_squared_error: 14.6201 - val_msle: 0.0526\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 4s 202ms/step - loss: 5.3803 - root_mean_squared_error: 13.3541 - msle: 0.0372 - val_loss: 6.0366 - val_root_mean_squared_error: 14.3784 - val_msle: 0.0503\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 4s 205ms/step - loss: 5.2266 - root_mean_squared_error: 13.4029 - msle: 0.0407 - val_loss: 5.9394 - val_root_mean_squared_error: 14.3200 - val_msle: 0.0320\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 4s 194ms/step - loss: 5.1844 - root_mean_squared_error: 13.0649 - msle: 0.0340 - val_loss: 6.2937 - val_root_mean_squared_error: 15.0643 - val_msle: 0.0368\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 4s 200ms/step - loss: 5.3998 - root_mean_squared_error: 13.7460 - msle: 0.0320 - val_loss: 5.8742 - val_root_mean_squared_error: 14.2430 - val_msle: 0.0375\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 4s 203ms/step - loss: 5.2698 - root_mean_squared_error: 13.2678 - msle: 0.0283 - val_loss: 5.9676 - val_root_mean_squared_error: 14.4721 - val_msle: 0.0314\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 4s 202ms/step - loss: 5.2142 - root_mean_squared_error: 13.2585 - msle: 0.0312 - val_loss: 5.9505 - val_root_mean_squared_error: 14.3291 - val_msle: 0.0425\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 4s 203ms/step - loss: 5.2368 - root_mean_squared_error: 13.1728 - msle: 0.0356 - val_loss: 6.0945 - val_root_mean_squared_error: 14.5761 - val_msle: 0.0376\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 4s 210ms/step - loss: 5.2292 - root_mean_squared_error: 13.1715 - msle: 0.0343 - val_loss: 6.1731 - val_root_mean_squared_error: 14.6598 - val_msle: 0.0457\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 4s 217ms/step - loss: 5.2796 - root_mean_squared_error: 13.4302 - msle: 0.0360 - val_loss: 5.8566 - val_root_mean_squared_error: 14.0353 - val_msle: 0.0434\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 4s 211ms/step - loss: 5.2126 - root_mean_squared_error: 12.9786 - msle: 0.0342 - val_loss: 5.8375 - val_root_mean_squared_error: 14.2717 - val_msle: 0.0337\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 4s 214ms/step - loss: 5.0794 - root_mean_squared_error: 13.0899 - msle: 0.0296 - val_loss: 5.8232 - val_root_mean_squared_error: 14.1764 - val_msle: 0.0348\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 5s 244ms/step - loss: 4.8944 - root_mean_squared_error: 12.3768 - msle: 0.0334 - val_loss: 5.8482 - val_root_mean_squared_error: 14.3276 - val_msle: 0.0478\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 5s 227ms/step - loss: 4.7830 - root_mean_squared_error: 12.0803 - msle: 0.0349 - val_loss: 5.6756 - val_root_mean_squared_error: 14.3256 - val_msle: 0.0280\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 5s 258ms/step - loss: 4.5305 - root_mean_squared_error: 11.7252 - msle: 0.0260 - val_loss: 5.8397 - val_root_mean_squared_error: 14.5811 - val_msle: 0.0363\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 5s 243ms/step - loss: 4.4746 - root_mean_squared_error: 11.4355 - msle: 0.0291 - val_loss: 5.7789 - val_root_mean_squared_error: 14.5547 - val_msle: 0.0335\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 4s 212ms/step - loss: 4.4734 - root_mean_squared_error: 11.4845 - msle: 0.0315 - val_loss: 5.6356 - val_root_mean_squared_error: 14.3144 - val_msle: 0.0299\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 4s 217ms/step - loss: 4.2569 - root_mean_squared_error: 10.9337 - msle: 0.0284 - val_loss: 5.5821 - val_root_mean_squared_error: 14.3783 - val_msle: 0.0440\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 4s 202ms/step - loss: 4.2409 - root_mean_squared_error: 11.0293 - msle: 0.0338 - val_loss: 5.6568 - val_root_mean_squared_error: 14.6101 - val_msle: 0.0374\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 4s 218ms/step - loss: 3.8012 - root_mean_squared_error: 10.0855 - msle: 0.0269 - val_loss: 5.7032 - val_root_mean_squared_error: 14.6605 - val_msle: 0.0438\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 5s 230ms/step - loss: 4.0211 - root_mean_squared_error: 10.3406 - msle: 0.0312 - val_loss: 5.6351 - val_root_mean_squared_error: 14.7103 - val_msle: 0.0300\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 4s 227ms/step - loss: 3.7372 - root_mean_squared_error: 9.6100 - msle: 0.0234 - val_loss: 5.5865 - val_root_mean_squared_error: 14.4247 - val_msle: 0.0371\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 4s 207ms/step - loss: 3.8190 - root_mean_squared_error: 9.9301 - msle: 0.0275 - val_loss: 5.8293 - val_root_mean_squared_error: 14.9286 - val_msle: 0.0368\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 4s 196ms/step - loss: 3.6414 - root_mean_squared_error: 9.6214 - msle: 0.0250 - val_loss: 6.1112 - val_root_mean_squared_error: 15.3084 - val_msle: 0.0350\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 4s 188ms/step - loss: 3.6055 - root_mean_squared_error: 9.2895 - msle: 0.0242 - val_loss: 5.8628 - val_root_mean_squared_error: 15.1474 - val_msle: 0.0292\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 4s 192ms/step - loss: 3.5819 - root_mean_squared_error: 9.2724 - msle: 0.0236 - val_loss: 5.9347 - val_root_mean_squared_error: 15.2527 - val_msle: 0.0360\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 4s 197ms/step - loss: 3.5220 - root_mean_squared_error: 9.2049 - msle: 0.0252 - val_loss: 6.1393 - val_root_mean_squared_error: 15.4569 - val_msle: 0.0308\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 4s 212ms/step - loss: 3.4387 - root_mean_squared_error: 8.8668 - msle: 0.0205 - val_loss: 6.1056 - val_root_mean_squared_error: 15.2680 - val_msle: 0.0291\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 4s 185ms/step - loss: 3.3040 - root_mean_squared_error: 8.7607 - msle: 0.0208 - val_loss: 6.0348 - val_root_mean_squared_error: 15.1320 - val_msle: 0.0397\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 5s 273ms/step - loss: 3.2337 - root_mean_squared_error: 8.3086 - msle: 0.0275 - val_loss: 6.0404 - val_root_mean_squared_error: 15.1916 - val_msle: 0.0371\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 4s 224ms/step - loss: 3.3457 - root_mean_squared_error: 8.8355 - msle: 0.0240 - val_loss: 6.0696 - val_root_mean_squared_error: 15.0044 - val_msle: 0.0377\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 5s 239ms/step - loss: 3.1994 - root_mean_squared_error: 8.3089 - msle: 0.0216 - val_loss: 6.2001 - val_root_mean_squared_error: 15.4412 - val_msle: 0.0353\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 5s 259ms/step - loss: 3.2548 - root_mean_squared_error: 8.5129 - msle: 0.0222 - val_loss: 6.3220 - val_root_mean_squared_error: 15.5613 - val_msle: 0.0423\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 5s 272ms/step - loss: 3.0348 - root_mean_squared_error: 7.8706 - msle: 0.0233 - val_loss: 6.2863 - val_root_mean_squared_error: 15.5010 - val_msle: 0.0345\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 4s 219ms/step - loss: 3.3066 - root_mean_squared_error: 8.5630 - msle: 0.0228 - val_loss: 6.1048 - val_root_mean_squared_error: 15.0594 - val_msle: 0.0299\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 5s 242ms/step - loss: 3.0856 - root_mean_squared_error: 8.2329 - msle: 0.0193 - val_loss: 5.9585 - val_root_mean_squared_error: 15.2184 - val_msle: 0.0295\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 5s 255ms/step - loss: 2.9924 - root_mean_squared_error: 8.0758 - msle: 0.0201 - val_loss: 6.1959 - val_root_mean_squared_error: 15.5289 - val_msle: 0.0372\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 5s 235ms/step - loss: 3.0254 - root_mean_squared_error: 8.0236 - msle: 0.0261 - val_loss: 6.3016 - val_root_mean_squared_error: 15.8465 - val_msle: 0.0365\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 4s 213ms/step - loss: 2.9619 - root_mean_squared_error: 8.0669 - msle: 0.0219 - val_loss: 6.0021 - val_root_mean_squared_error: 15.3036 - val_msle: 0.0342\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 4s 220ms/step - loss: 2.9242 - root_mean_squared_error: 7.9613 - msle: 0.0210 - val_loss: 5.9375 - val_root_mean_squared_error: 15.3059 - val_msle: 0.0325\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 4s 220ms/step - loss: 2.9864 - root_mean_squared_error: 8.0015 - msle: 0.0205 - val_loss: 6.0919 - val_root_mean_squared_error: 15.4481 - val_msle: 0.0317\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 6s 281ms/step - loss: 3.0456 - root_mean_squared_error: 8.0510 - msle: 0.0215 - val_loss: 6.1032 - val_root_mean_squared_error: 15.4863 - val_msle: 0.0328\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 5s 257ms/step - loss: 3.1289 - root_mean_squared_error: 8.1052 - msle: 0.0218 - val_loss: 6.0257 - val_root_mean_squared_error: 15.4292 - val_msle: 0.0340\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 5s 274ms/step - loss: 3.0558 - root_mean_squared_error: 8.0026 - msle: 0.0230 - val_loss: 5.9513 - val_root_mean_squared_error: 15.4306 - val_msle: 0.0371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-b5kvK9Hmyy",
        "outputId": "3f36221b-03af-49d6-bab9-612838e46d94"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 61ms/step - loss: 5.9513 - root_mean_squared_error: 15.4306 - msle: 0.0371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.951345920562744, 15.4306001663208, 0.037071701139211655]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "source": [
        "# Get weights of movie scripts"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdmnTnU9yorr"
      },
      "source": [
        "def stringProcessing(s):\n",
        "    s = re.sub(r\"\\'\", \"\", s)\n",
        "    s = re.sub(r'\\n', ' ', s)\n",
        "    s = re.sub(r'\\t', '', s)\n",
        "    s = re.sub(r\"\\[[^[]*\\]\", '', s)\n",
        "    s = re.sub(r'[^\\w\\s]', ' ', s)\n",
        "    s = re.sub(r' +', ' ', s)\n",
        "    s = s.strip()\n",
        "    s = s.lower()\n",
        "    return s\n",
        "def vectorize_movie_scripts(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JkN7CMcstmH",
        "outputId": "685c0aab-6549-4efc-f9cc-8ec6d7fa80ce"
      },
      "source": [
        "import os\n",
        "# model = create_model(\n",
        "\n",
        "# df = pd.read_csv(\"https://raw.githubusercontent.com/benbrill/MoodSpace/main/data/trainingSongs_clean.csv\")\n",
        "\n",
        "# data = tf.data.Dataset.from_tensor_slices((df[\"lyrics\"]))\n",
        "# data_vec = data.map(vectorize_headline)\n",
        "# df = pd.DataFrame(model.predict(data_vec))\n",
        "# df.shape\n",
        "d = {}\n",
        "for script_path in os.listdir(\"../scripts\"):\n",
        "    with open(f\"../scripts/{script_path}\") as f:\n",
        "        contents = f.read()\n",
        "\n",
        "        contents = stringProcessing(contents)\n",
        "\n",
        "        df = pd.DataFrame({\"lyrics\": [contents]})\n",
        "        \n",
        "        vectorize_layer.adapt(df[\"lyrics\"].to_numpy())\n",
        "        X = vectorize_layer(df[\"lyrics\"])\n",
        "        pred = model.predict(X)\n",
        "        # pred = np.concatenate((pred[0], pred[1], pred[2], pred[3]), axis = 1)\n",
        "        d[script_path] = pred\n",
        "        print(script_path, pred)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bourne.txt [[  0.71360993   0.320662   114.09092      0.22432168]]\n",
            "deadpoets.txt [[  0.78789055   0.3145327  144.72891      0.2883013 ]]\n",
            "fellowship.txt [[ 0.6388979   0.27172333 79.601       0.21370538]]\n",
            "forrest.txt [[  0.72052824   0.33857027 108.75427      0.21457465]]\n",
            "goodwillhunting.txt [[  0.77706635   0.3820778  117.168495     0.2549017 ]]\n",
            "incredibles.txt [[  0.71231747   0.3399482  103.409515     0.19998653]]\n",
            "jedi.txt [[  0.795776    0.3377211 131.24046     0.2809444]]\n",
            "khan.txt [[  0.74088526   0.27247956 131.70927      0.2648602 ]]\n",
            "shawshank.txt [[  0.7348423    0.23269916 140.84998      0.27799922]]\n",
            "titanic.txt [[ 0.6943335   0.33119333 97.17831     0.19266303]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSrMZbZkzjAF"
      },
      "source": [
        "model.save_weights(\"my_checkpoint_30\") # save weights to avoid retraining the model in the backend"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}