{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfLyricClassifcation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4n0KZpbZINvFVaDbqU/Dq"
    },
    "kernelspec": {
      "name": "python395jvsc74a57bd063a8339a2b998405504b80cac15dbfc0480b6c1c806e16474572f1b40b735ee0",
      "display_name": "Python 3.9.5 64-bit ('env': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "63a8339a2b998405504b80cac15dbfc0480b6c1c806e16474572f1b40b735ee0"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gimym_e08Xr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "# requires update to tensorflow 2.4\n",
        "# >>> conda activate PIC16B\n",
        "# >>> pip install tensorflow==2.4\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "source": [
        "# Import Data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xjv0ShaR1GO1",
        "outputId": "c8471504-b3ab-47c0-bd90-77a9502eb244"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/benbrill/MoodSpace/main/data/trainingSongs_clean.csv\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                        trackName          artist  \\\n",
              "0           3                      Overthinker            INZO   \n",
              "1           4  Lifestyles of the Rich & Famous  Good Charlotte   \n",
              "2           6       Carrying Your Love With Me   George Strait   \n",
              "3           7                Check Yes, Juliet    We The Kings   \n",
              "4           8      At My Worst (feat. Kehlani)     Pink Sweat$   \n",
              "\n",
              "                       id  danceability  energy   key  loudness  mode  \\\n",
              "0  4K9xid96G3YmIvQZXN9SXg         0.472   0.605   8.0    -4.437   1.0   \n",
              "1  2g2a5kDeZexbUTD8abcvm6         0.620   0.930   1.0    -3.685   1.0   \n",
              "2  7puxIVNdj5nsBJk43zM3bH         0.629   0.479  10.0   -10.608   1.0   \n",
              "3  0wVluBsVAVzBKrqspuCcwR         0.352   0.912   7.0    -4.253   1.0   \n",
              "4  58w68w4s8h9gw3xrDaXyuj         0.731   0.484   0.0    -5.579   1.0   \n",
              "\n",
              "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
              "0       0.1340       0.03110          0.030800    0.1010    0.212  128.375   \n",
              "1       0.0374       0.00043          0.000000    0.0686    0.609  106.220   \n",
              "2       0.0271       0.22000          0.000000    0.0587    0.345  138.231   \n",
              "3       0.0725       0.00197          0.000000    0.1930    0.351  166.795   \n",
              "4       0.0354       0.73000          0.000003    0.3260    0.350   92.043   \n",
              "\n",
              "             type                                             lyrics  cluster  \\\n",
              "0  audio_features  a person who thinks all the time has nothing t...        0   \n",
              "1  audio_features  always see it on t v or read in the magazines ...        3   \n",
              "2  audio_features  baby all i got is this beat up leather bag and...        5   \n",
              "3  audio_features  check yes juliet are you with me rain is falli...        2   \n",
              "4  audio_features  can i call you baby can you be my friend can y...        1   \n",
              "\n",
              "  language  \n",
              "0       en  \n",
              "1       en  \n",
              "2       en  \n",
              "3       en  \n",
              "4       en  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>trackName</th>\n      <th>artist</th>\n      <th>id</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>type</th>\n      <th>lyrics</th>\n      <th>cluster</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Overthinker</td>\n      <td>INZO</td>\n      <td>4K9xid96G3YmIvQZXN9SXg</td>\n      <td>0.472</td>\n      <td>0.605</td>\n      <td>8.0</td>\n      <td>-4.437</td>\n      <td>1.0</td>\n      <td>0.1340</td>\n      <td>0.03110</td>\n      <td>0.030800</td>\n      <td>0.1010</td>\n      <td>0.212</td>\n      <td>128.375</td>\n      <td>audio_features</td>\n      <td>a person who thinks all the time has nothing t...</td>\n      <td>0</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Lifestyles of the Rich &amp; Famous</td>\n      <td>Good Charlotte</td>\n      <td>2g2a5kDeZexbUTD8abcvm6</td>\n      <td>0.620</td>\n      <td>0.930</td>\n      <td>1.0</td>\n      <td>-3.685</td>\n      <td>1.0</td>\n      <td>0.0374</td>\n      <td>0.00043</td>\n      <td>0.000000</td>\n      <td>0.0686</td>\n      <td>0.609</td>\n      <td>106.220</td>\n      <td>audio_features</td>\n      <td>always see it on t v or read in the magazines ...</td>\n      <td>3</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>Carrying Your Love With Me</td>\n      <td>George Strait</td>\n      <td>7puxIVNdj5nsBJk43zM3bH</td>\n      <td>0.629</td>\n      <td>0.479</td>\n      <td>10.0</td>\n      <td>-10.608</td>\n      <td>1.0</td>\n      <td>0.0271</td>\n      <td>0.22000</td>\n      <td>0.000000</td>\n      <td>0.0587</td>\n      <td>0.345</td>\n      <td>138.231</td>\n      <td>audio_features</td>\n      <td>baby all i got is this beat up leather bag and...</td>\n      <td>5</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>Check Yes, Juliet</td>\n      <td>We The Kings</td>\n      <td>0wVluBsVAVzBKrqspuCcwR</td>\n      <td>0.352</td>\n      <td>0.912</td>\n      <td>7.0</td>\n      <td>-4.253</td>\n      <td>1.0</td>\n      <td>0.0725</td>\n      <td>0.00197</td>\n      <td>0.000000</td>\n      <td>0.1930</td>\n      <td>0.351</td>\n      <td>166.795</td>\n      <td>audio_features</td>\n      <td>check yes juliet are you with me rain is falli...</td>\n      <td>2</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>At My Worst (feat. Kehlani)</td>\n      <td>Pink Sweat$</td>\n      <td>58w68w4s8h9gw3xrDaXyuj</td>\n      <td>0.731</td>\n      <td>0.484</td>\n      <td>0.0</td>\n      <td>-5.579</td>\n      <td>1.0</td>\n      <td>0.0354</td>\n      <td>0.73000</td>\n      <td>0.000003</td>\n      <td>0.3260</td>\n      <td>0.350</td>\n      <td>92.043</td>\n      <td>audio_features</td>\n      <td>can i call you baby can you be my friend can y...</td>\n      <td>1</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "source": [
        "# Create Text Vectorization"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDTSMbEC2Szp"
      },
      "source": [
        "max_tokens = 200\n",
        "sequence_length = 500\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_tokens, # only consider this many words\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W_PQpzv2W2E"
      },
      "source": [
        "data = tf.data.Dataset.from_tensor_slices((df[\"lyrics\"], df[\"cluster\"]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbmJ12El3UdI",
        "outputId": "aaf33015-32d9-4051-800a-0dc7472d198e"
      },
      "source": [
        "data = data.shuffle(buffer_size = len(data))\n",
        "\n",
        "train_size = int(0.7*len(data))\n",
        "val_size   = int(0.1*len(data))\n",
        "\n",
        "vectorize_layer.adapt(data)\n",
        "\n",
        "train = data.take(train_size)\n",
        "val   = data.skip(train_size).take(val_size)\n",
        "test  = data.skip(train_size + val_size)\n",
        "len(train), len(val), len(test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The dataset passed to 'adapt' must contain a single tensor value.",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-6315ded5738d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_size\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvectorize_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\brill\\OneDrive\\Documents\\uCLA\\PIC16B\\PIC16B-Project\\env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, data, reset_state)\u001b[0m\n\u001b[0;32m    400\u001b[0m       \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_legacy_output_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         raise ValueError(\"The dataset passed to 'adapt' must contain a single \"\n\u001b[0m\u001b[0;32m    403\u001b[0m                          \"tensor value.\")\n\u001b[0;32m    404\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: The dataset passed to 'adapt' must contain a single tensor value."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xft9VRhW40BB"
      },
      "source": [
        "def vectorize_movie_script(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), [label]\n",
        "\n",
        "train_vec = train.map(vectorize_movie_script)\n",
        "val_vec   = val.map(vectorize_movie_script)\n",
        "test_vec  = test.map(vectorize_movie_script)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "source": [
        "# Create Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NTNTIBe4dST"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_tokens, output_dim = 10, name=\"embedding\"),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(8)]\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBvK_cSd4iNS"
      },
      "source": [
        "model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOvPCjkg4oD4",
        "outputId": "90aca939-e584-40bb-e647-84aab7ab9192"
      },
      "source": [
        "history = model.fit(train_vec, epochs = 100, validation_data = val_vec)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "501/501 [==============================] - 3s 3ms/step - loss: 2.0551 - accuracy: 0.1527 - val_loss: 1.9799 - val_accuracy: 0.1408\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.9672 - accuracy: 0.1771 - val_loss: 1.9176 - val_accuracy: 0.2817\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.9345 - accuracy: 0.1830 - val_loss: 1.8964 - val_accuracy: 0.2113\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8922 - accuracy: 0.2253 - val_loss: 1.8152 - val_accuracy: 0.3239\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8866 - accuracy: 0.2111 - val_loss: 1.8606 - val_accuracy: 0.2394\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8955 - accuracy: 0.1835 - val_loss: 1.9304 - val_accuracy: 0.2535\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8831 - accuracy: 0.2061 - val_loss: 1.8494 - val_accuracy: 0.2535\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8440 - accuracy: 0.2192 - val_loss: 1.9222 - val_accuracy: 0.2254\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.9043 - accuracy: 0.1607 - val_loss: 1.8745 - val_accuracy: 0.2676\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8508 - accuracy: 0.1981 - val_loss: 1.9188 - val_accuracy: 0.2254\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8266 - accuracy: 0.2449 - val_loss: 1.8953 - val_accuracy: 0.2254\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8547 - accuracy: 0.1969 - val_loss: 1.9757 - val_accuracy: 0.1408\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.9047 - accuracy: 0.2113 - val_loss: 1.9545 - val_accuracy: 0.1127\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8796 - accuracy: 0.2113 - val_loss: 1.8530 - val_accuracy: 0.2535\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8782 - accuracy: 0.2465 - val_loss: 1.8196 - val_accuracy: 0.1831\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8851 - accuracy: 0.2069 - val_loss: 1.8136 - val_accuracy: 0.3239\n",
            "Epoch 17/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.9174 - accuracy: 0.2213 - val_loss: 1.8043 - val_accuracy: 0.2676\n",
            "Epoch 18/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8661 - accuracy: 0.2302 - val_loss: 1.8283 - val_accuracy: 0.3099\n",
            "Epoch 19/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8964 - accuracy: 0.1907 - val_loss: 1.8149 - val_accuracy: 0.2958\n",
            "Epoch 20/100\n",
            "501/501 [==============================] - 2s 3ms/step - loss: 1.8814 - accuracy: 0.1958 - val_loss: 1.8765 - val_accuracy: 0.1127\n",
            "Epoch 21/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8884 - accuracy: 0.1827 - val_loss: 1.8761 - val_accuracy: 0.1690\n",
            "Epoch 22/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8819 - accuracy: 0.2338 - val_loss: 1.8818 - val_accuracy: 0.1972\n",
            "Epoch 23/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8612 - accuracy: 0.2438 - val_loss: 1.9477 - val_accuracy: 0.2958\n",
            "Epoch 24/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8529 - accuracy: 0.2340 - val_loss: 1.8734 - val_accuracy: 0.2958\n",
            "Epoch 25/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8762 - accuracy: 0.2571 - val_loss: 1.8056 - val_accuracy: 0.4085\n",
            "Epoch 26/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8833 - accuracy: 0.2317 - val_loss: 1.8897 - val_accuracy: 0.1690\n",
            "Epoch 27/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8654 - accuracy: 0.2542 - val_loss: 1.8365 - val_accuracy: 0.1972\n",
            "Epoch 28/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8668 - accuracy: 0.2617 - val_loss: 1.8466 - val_accuracy: 0.2254\n",
            "Epoch 29/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8417 - accuracy: 0.2687 - val_loss: 1.8124 - val_accuracy: 0.2817\n",
            "Epoch 30/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8266 - accuracy: 0.3071 - val_loss: 1.8333 - val_accuracy: 0.2113\n",
            "Epoch 31/100\n",
            "501/501 [==============================] - 1s 1ms/step - loss: 1.8404 - accuracy: 0.2341 - val_loss: 1.8676 - val_accuracy: 0.2817\n",
            "Epoch 32/100\n",
            "501/501 [==============================] - 1s 1ms/step - loss: 1.8462 - accuracy: 0.2471 - val_loss: 1.8435 - val_accuracy: 0.2676\n",
            "Epoch 33/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8721 - accuracy: 0.2611 - val_loss: 1.8443 - val_accuracy: 0.3239\n",
            "Epoch 34/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8440 - accuracy: 0.2875 - val_loss: 1.8300 - val_accuracy: 0.2535\n",
            "Epoch 35/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8658 - accuracy: 0.2531 - val_loss: 1.8363 - val_accuracy: 0.2676\n",
            "Epoch 36/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8044 - accuracy: 0.2914 - val_loss: 1.8013 - val_accuracy: 0.3099\n",
            "Epoch 37/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8979 - accuracy: 0.2362 - val_loss: 1.7806 - val_accuracy: 0.3239\n",
            "Epoch 38/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8316 - accuracy: 0.3075 - val_loss: 1.7942 - val_accuracy: 0.3380\n",
            "Epoch 39/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8239 - accuracy: 0.2481 - val_loss: 1.8206 - val_accuracy: 0.2113\n",
            "Epoch 40/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8461 - accuracy: 0.2740 - val_loss: 1.8814 - val_accuracy: 0.2535\n",
            "Epoch 41/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8665 - accuracy: 0.2679 - val_loss: 1.9155 - val_accuracy: 0.1972\n",
            "Epoch 42/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8609 - accuracy: 0.2451 - val_loss: 1.7680 - val_accuracy: 0.3662\n",
            "Epoch 43/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8661 - accuracy: 0.2195 - val_loss: 1.8550 - val_accuracy: 0.3239\n",
            "Epoch 44/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8715 - accuracy: 0.2113 - val_loss: 1.8155 - val_accuracy: 0.3099\n",
            "Epoch 45/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8668 - accuracy: 0.2738 - val_loss: 1.8288 - val_accuracy: 0.2676\n",
            "Epoch 46/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8787 - accuracy: 0.2482 - val_loss: 1.8711 - val_accuracy: 0.2113\n",
            "Epoch 47/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8649 - accuracy: 0.2621 - val_loss: 1.8805 - val_accuracy: 0.2254\n",
            "Epoch 48/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8303 - accuracy: 0.2804 - val_loss: 1.8490 - val_accuracy: 0.2394\n",
            "Epoch 49/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8532 - accuracy: 0.2657 - val_loss: 1.8858 - val_accuracy: 0.2394\n",
            "Epoch 50/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8400 - accuracy: 0.2594 - val_loss: 1.8553 - val_accuracy: 0.2535\n",
            "Epoch 51/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.9069 - accuracy: 0.2547 - val_loss: 1.8299 - val_accuracy: 0.1972\n",
            "Epoch 52/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8669 - accuracy: 0.2566 - val_loss: 1.8427 - val_accuracy: 0.2535\n",
            "Epoch 53/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8928 - accuracy: 0.2493 - val_loss: 1.7950 - val_accuracy: 0.3380\n",
            "Epoch 54/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8919 - accuracy: 0.2223 - val_loss: 1.8639 - val_accuracy: 0.2394\n",
            "Epoch 55/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8395 - accuracy: 0.2800 - val_loss: 1.7982 - val_accuracy: 0.2535\n",
            "Epoch 56/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8512 - accuracy: 0.2420 - val_loss: 1.8626 - val_accuracy: 0.2254\n",
            "Epoch 57/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8525 - accuracy: 0.2341 - val_loss: 1.8208 - val_accuracy: 0.2676\n",
            "Epoch 58/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8424 - accuracy: 0.2741 - val_loss: 1.9182 - val_accuracy: 0.1972\n",
            "Epoch 59/100\n",
            "501/501 [==============================] - 1s 1ms/step - loss: 1.8611 - accuracy: 0.2464 - val_loss: 1.8372 - val_accuracy: 0.2535\n",
            "Epoch 60/100\n",
            "501/501 [==============================] - 1s 1ms/step - loss: 1.8636 - accuracy: 0.2346 - val_loss: 1.8076 - val_accuracy: 0.2676\n",
            "Epoch 61/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8447 - accuracy: 0.2606 - val_loss: 1.8283 - val_accuracy: 0.1831\n",
            "Epoch 62/100\n",
            "501/501 [==============================] - 1s 1ms/step - loss: 1.8307 - accuracy: 0.2669 - val_loss: 1.8078 - val_accuracy: 0.2676\n",
            "Epoch 63/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8993 - accuracy: 0.2207 - val_loss: 1.8297 - val_accuracy: 0.2113\n",
            "Epoch 64/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8701 - accuracy: 0.2456 - val_loss: 1.8711 - val_accuracy: 0.2394\n",
            "Epoch 65/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8629 - accuracy: 0.2549 - val_loss: 1.7581 - val_accuracy: 0.3099\n",
            "Epoch 66/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8476 - accuracy: 0.2536 - val_loss: 1.8927 - val_accuracy: 0.2535\n",
            "Epoch 67/100\n",
            "501/501 [==============================] - 1s 1ms/step - loss: 1.8675 - accuracy: 0.2772 - val_loss: 1.8298 - val_accuracy: 0.2394\n",
            "Epoch 68/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8636 - accuracy: 0.2440 - val_loss: 1.8476 - val_accuracy: 0.2113\n",
            "Epoch 69/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8730 - accuracy: 0.1907 - val_loss: 1.9052 - val_accuracy: 0.2113\n",
            "Epoch 70/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8379 - accuracy: 0.2665 - val_loss: 1.7846 - val_accuracy: 0.3099\n",
            "Epoch 71/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8903 - accuracy: 0.2671 - val_loss: 1.9195 - val_accuracy: 0.2113\n",
            "Epoch 72/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8329 - accuracy: 0.2725 - val_loss: 1.7970 - val_accuracy: 0.3380\n",
            "Epoch 73/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8354 - accuracy: 0.2413 - val_loss: 1.9367 - val_accuracy: 0.2254\n",
            "Epoch 74/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.9072 - accuracy: 0.2390 - val_loss: 1.8017 - val_accuracy: 0.2817\n",
            "Epoch 75/100\n",
            "501/501 [==============================] - 1s 3ms/step - loss: 1.8149 - accuracy: 0.2839 - val_loss: 1.8540 - val_accuracy: 0.2676\n",
            "Epoch 76/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8446 - accuracy: 0.2654 - val_loss: 1.8594 - val_accuracy: 0.1831\n",
            "Epoch 77/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8592 - accuracy: 0.2760 - val_loss: 1.7916 - val_accuracy: 0.2535\n",
            "Epoch 78/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8515 - accuracy: 0.2454 - val_loss: 1.8365 - val_accuracy: 0.2958\n",
            "Epoch 79/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8078 - accuracy: 0.2944 - val_loss: 1.8388 - val_accuracy: 0.2254\n",
            "Epoch 80/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8332 - accuracy: 0.2880 - val_loss: 1.8699 - val_accuracy: 0.2254\n",
            "Epoch 81/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.9062 - accuracy: 0.2204 - val_loss: 1.7920 - val_accuracy: 0.2958\n",
            "Epoch 82/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8688 - accuracy: 0.2435 - val_loss: 1.8818 - val_accuracy: 0.2113\n",
            "Epoch 83/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8322 - accuracy: 0.2779 - val_loss: 1.8878 - val_accuracy: 0.2394\n",
            "Epoch 84/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8543 - accuracy: 0.2289 - val_loss: 1.8881 - val_accuracy: 0.2113\n",
            "Epoch 85/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8621 - accuracy: 0.2758 - val_loss: 1.8682 - val_accuracy: 0.2817\n",
            "Epoch 86/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8665 - accuracy: 0.2519 - val_loss: 1.8031 - val_accuracy: 0.2958\n",
            "Epoch 87/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8443 - accuracy: 0.2461 - val_loss: 1.8876 - val_accuracy: 0.2254\n",
            "Epoch 88/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8371 - accuracy: 0.2741 - val_loss: 1.8846 - val_accuracy: 0.2394\n",
            "Epoch 89/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8313 - accuracy: 0.2485 - val_loss: 1.8209 - val_accuracy: 0.1972\n",
            "Epoch 90/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8190 - accuracy: 0.2747 - val_loss: 1.7992 - val_accuracy: 0.2817\n",
            "Epoch 91/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8477 - accuracy: 0.2792 - val_loss: 1.7960 - val_accuracy: 0.2535\n",
            "Epoch 92/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8205 - accuracy: 0.2803 - val_loss: 1.7924 - val_accuracy: 0.2817\n",
            "Epoch 93/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8675 - accuracy: 0.2045 - val_loss: 1.8454 - val_accuracy: 0.3521\n",
            "Epoch 94/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8699 - accuracy: 0.2576 - val_loss: 1.8789 - val_accuracy: 0.2817\n",
            "Epoch 95/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8587 - accuracy: 0.2671 - val_loss: 1.8190 - val_accuracy: 0.2958\n",
            "Epoch 96/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8994 - accuracy: 0.2626 - val_loss: 1.7985 - val_accuracy: 0.3380\n",
            "Epoch 97/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8631 - accuracy: 0.2594 - val_loss: 1.8409 - val_accuracy: 0.1972\n",
            "Epoch 98/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8799 - accuracy: 0.2315 - val_loss: 1.9007 - val_accuracy: 0.2394\n",
            "Epoch 99/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 1.8402 - accuracy: 0.2722 - val_loss: 1.8180 - val_accuracy: 0.3239\n",
            "Epoch 100/100\n",
            "501/501 [==============================] - 1s 2ms/step - loss: 1.8186 - accuracy: 0.3111 - val_loss: 1.8835 - val_accuracy: 0.2113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb46vkB14utk",
        "outputId": "032e3899-bc5c-41c2-ffb5-78c0b81f1266"
      },
      "source": [
        "model.predict(test_vec)[1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.5185795e-01,  4.9152628e-01, -2.3496413e-01, -6.6743582e-02,\n",
              "       -2.0310804e-03,  3.1183892e-01, -9.1974133e-01, -4.3409243e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145/145 [==============================] - 0s 928us/step - loss: 1.8582 - accuracy: 0.2483\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8582499027252197, 0.24827586114406586]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.evaluate(test_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}